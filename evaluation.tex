\chapter{Evaluation}

\subsection{Environment}

All the code has been run on the "Astral" high performance computer of Cranfield's university. The operating system is SUSE Linux Enterprise Server 11 (64 bits architecture), with a Linux 3 kernel.

The system is separated in login nodes and compute nodes. There are two "front-end" login nodes and they contain two Intel E5-2660 (Sandy Bridge - 8 cores) CPUs giving 16 CPU cores and have a total of 192 GB of shared memory. The login nodes enable the user to connect to the system and compile one's program. There are 80 compute nodes, each node having two Intel E5-2660 (Sandy Bridge - 8 cores) CPUs. This is giving a total of 1280 available cores. Each compute node have at least accessed to 64 GB shared memory. Nodes are connected with Infiniband\TM low-latency interconnect.

\subsection{Segmentation metrics}

\footnote{Information on the evaluation system can be found at  \url{http://host.robots.ox.ac.uk/pascal/VOC/voc2012/devkit_doc.pdf}}

To measure the precision of the localization / segmentation algorithm, we use the metrics as defined in \cite{pascalVoc2012}.

Detections are considered true or false positives based on the area of overlap with ground truth bounding boxes. To be considered a correct detection, the \textbf{Intersection over Union} $IoU$ between the predicted bounding box $B_p$ and ground truth bounding box $B_{gt}$ must exceed 50\% by the formula:

$$IoU = \frac{area(B_p \cap B_{gt})}{area(B_p \cup B_{gt})}$$

To simplify the calculation, this formula can be rewritten as:

$$IoU = \frac{area(B_p \cap B_{gt})}{area(B_p) + area(B_{gt}) - area(B_p \cap B_{gt})} $$

Using this metric, we can compute the precision $P$, the recall $R$ and the accuracy $A$ given by:

$$ P =  \frac{T_p}{T_p + F_p}$$
$$ R =  \frac{T_p}{T_p + F_n}$$
$$ A = \frac{T_p}{T_p + F_n + F_p} $$

with:
\begin{itemize}
   \item $T_p$ the number of true positives (the bounding boxes correctly localized)
   \item $F_p$ the number of false positives (the predicted bounding boxes incorrectly localized)
   \item $F_n$ the number of false negative (the ground truth bounding boxes not localized)
\end{itemize}

Note that given the convention from \cite{pascalVoc2012}, if more than one predicted bounding box overlaps the same ground truth bounding box, only one will be considered as $T_P$, the rest will be $F_P$s.

\subsection{Classification metrics}

% http://scikit-learn.org/stable/modules/cross_validation.html
cross validation
accuracy
% http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion\_matrix.html
confusion matrix

\section{Results}
\subsection{Food segmentation}



\subsection{Classification}

For using 10 fold cross validation
without parameters optimization

using LBP (98 bins) + HS (30 * 30 bins) + mean and variance of each RGB channel + Hu-moments
\begin{itemize}
    \item random forest: 21 \% (250 trees, gini)
    \item decision tree: 6 \% (gini)
    \item k-nearest neighborhood: (k=10, distance metric: minkowski, weights of each neighborhood point: uniform): 10 \%
    \item SGD classifier:  12 \%
    \item Gaussian Naive Bayesian: 7 \%
    \item Linear SVM: 9 \% (no kernel trick)
    \item AdaBoost with decision tree: 4 \% (SAMME.R algorithm)
\end{itemize}

using a 2500-word codebook, root-sift, k-mean, RF (500 trees): 10 \% 

using the CNN + Random forest (500 trees): 48 \%

In \cite{Bolanos2016}, the authors use fine-tuned pre-trained Deep Neural Network and obtain 63 \% accuracyon UEC FOOD-256.

In \cite{Yanai2015}, the authors use fine-tuned pre-trained Deep Neural Network and obtain 67 \% accuracyon UEC FOOD-256.


\subsection{Segmentation followed by classification}

\cite{Bolanos2016} : accuracy 36.84 \%, 54.44 \% precision, Recall 50.86 \%
