\chapter{Methodology}

As illustrated in Fig. \ref{fig:tikz_methodology}, we have our initial dataset that we split in :
\begin{itemize}
    \item a \textbf{validation set} (10 \% of the dataset) used for hyper-parameter optimization or model selection for localisation and classification
    \item a \textbf{train / test set} (remaining dataset) used for the localisation and classification
\end{itemize}

\begin{figure}[h]
    \centering
    \tikzstyle{block} = [rectangle, draw, text width=3cm, text centered, rounded corners,  fill=blue!20]
    \tikzstyle{line} = [draw,thick, -latex']
    \tikzstyle{cloud} = [draw, ellipse, text width=3cm, text centered]
    \tikzstyle{edge from parent}=[->,thick,draw]
    \begin{tikzpicture}[auto, edge from parent fork down]
        % Distance between node
        \tikzstyle{level 1}=[sibling distance=80mm,level distance=10ex]
        
        % Place nodes
        \node [cloud, fill=red!10] (base) {Dataset}
        child{node [cloud, fill=green!10] (validation) {Validation set}
            child{node [block, fill=blue!10] (hyperparameter) {Hyper-parameter optimization}}
        }
        child{node [cloud, fill=green!10] (train_test) {Train / test sets}
            child{node [block, fill=blue!10] (localisation) {Localisation}
                child {node[block, fill=blue!10](feature){Feature description}
                    child {node[block, fill=blue!10](classification){Classification}
                        child {node[block, fill=red!10](result){Result}
                        }
                    }
                }
            }
        };
        % Draw edges
        \path [line] (hyperparameter.east) -- (localisation.west);
        \path [line] (hyperparameter.south) -- (classification.west);
    \end{tikzpicture}
    \caption{General process of the localisation and classification}
    \label{fig:tikz_methodology}
\end{figure}

\section{Hyperparameter optimization}

There are numerous parameters that are part of the machine learning but are not learnt. Typical example include which kernel function used (if any) or the value of the penalty parameter $C$ for SVM, the number of $k$ of neighborhoods for kNN.

We use the exhaustive grid search method to select the parameters that have the highest performance score through 10 fold cross validation. It generates all the possible combination of parameters value and train / test the classifier.

\section{Classification}

\subsection{Histograms and moments}

For each picture:
\begin{enumerate}
    \item extract the sub-image delimited by the bounding box
    \item resize this sub-image to $224 \times 224$ pixels
    \item extract the histogram of local binary pattern on the grayscale image
    \item extract the joint color histogram for the channel $H$ and $s$ of the HSV (hue, saturation and value) representation
    \item extract the first two moments on the R, G, B, H, S and Gray channels
    \item extract the 7 hu-moment
\end{enumerate}

The feature vectors are then normalized to have all features centered around zero (mean equal to 0) and have unit variance (equal to 1).

Then, apply multiple classifiers:
\begin{itemize}
    \item decision tree
    \item random forest (made up of 500 trees)
    \item SVM
\end{itemize}

hyperparameter optimization: using a grid
Try to optimize the accuracy for each classifier
Separate the dataset in 3, 10 \% for validation, 10 cross validation to select the best parameters
Then 10 cross validations to train and test the classifier

Talk in result: show the best amelioration with hyperparemeter (but in general it only improve it by one or two percents)

\subsection{Bag of words}

For each picture:
\begin{enumerate}
    \item extract the sub-image delimited by the bounding box
    \item resize this sub-image to $224 \times 224$ pixels
    \item detection of keypoints: use of a dense grid
    \item descriptors: Root SIFT. Root SIFT is a simple variant of SIFT, presented in \cite{Arandjelovic2012}. When the SIFT descriptors as been computed for each keypoints, we apply an element wise square root of the L1 normalized SIFT vectors
\end{enumerate}

clustering: using the k-means algorithm to obtain a 2500-word codebook.

For each picture:
compute the histogram of occurence counts of visual words

Kernel trick: use of a variant of the $\chi^2$ kernel named additive $\chi$-squared kernel presented in \cite{Vedaldi2010}

Then we apply the SVM classifier.

\subsection{CNN}

A pre-trained CNN used for image recognition on ImageNet Challenge 2014.

\cite{Simonyan2014}

it is available \footnote{\url{https://gist.github.com/ksimonyan/3785162f95cd2d5fee77/}}.

The model is an improved version of the 19-layer model used by the VGG team in the ILSVRC-2014 competition.

\section{Segmentation}

A pre-trained CNN used for saliency detection.

\cite{zhang2015SOD}

it is available \footnote{\url{https://gist.github.com/jimmie33/339fd0a938ed026692267a60b44c0c58}}.

It is the same model as GoogleNet model. It is composed of 19 layers.

\section{Code}

The code is public \footnote{\url{https://github.com/bnogaret/food_log}}.

Using python 3.5.2 and its scientific stack (numpy, scipy, matplotlib)
For the data structure: pandas \cite{McKinney2010}
For the image processing: scikit-image \cite{VanderWalt2014}
For most of the machine learning: package: sklearn \cite{Pedregosa2012}
For the CNN framework: caffe framework \cite{Jia2014a} (using the pyhton layer)
SIFT implementation: opencv 3.1 \cite{Bradski2000}

Documentation is generated from the python file using sphinx.