\chapter{Evaluation}

\subsection{Environment}

All the code has been run on the \enquote{Astral} high performance computer of Cranfield's university. The operating system is SUSE Linux Enterprise Server 11 (64 bits architecture), with a Linux 3 kernel.

The system is separated in login nodes and compute nodes. There are two \enquote{front-end} login nodes and they contain two Intel E5-2660 (Sandy Bridge - 8 cores) CPUs giving 16 CPU cores and have a total of 192 GB of shared memory. The login nodes enable the user to connect to the system and compile one's program. There are 80 compute nodes, each node having two Intel E5-2660 (Sandy Bridge - 8 cores) CPUs. This is giving a total of 1280 available cores. Each compute node have at least accessed to 64 GB shared memory. Nodes are connected with Infiniband\TM low-latency interconnect.

\subsection{Segmentation metrics}

\footnote{Information on the evaluation system can be found at  \url{http://host.robots.ox.ac.uk/pascal/VOC/voc2012/devkit_doc.pdf}}

To measure the precision of the localization / segmentation algorithm, we use the metrics as defined in \cite{pascalVoc2012}.

Detections are considered true or false positives based on the area of overlap with ground truth bounding boxes. To be considered a correct detection, the \textbf{Intersection over Union} $IoU$ between the predicted bounding box $B_p$ and ground truth bounding box $B_{gt}$ must exceed 50\% by the formula:

$$IoU = \frac{area(B_p \cap B_{gt})}{area(B_p \cup B_{gt})}$$

To simplify the calculation, this formula can be rewritten as:

$$IoU = \frac{area(B_p \cap B_{gt})}{area(B_p) + area(B_{gt}) - area(B_p \cap B_{gt})} $$

Using this metric, we can compute the precision $P$, the recall $R$ and the accuracy $A$ given by:

$$ P =  \frac{T_p}{T_p + F_p}$$
$$ R =  \frac{T_p}{T_p + F_n}$$
$$ A = \frac{T_p}{T_p + F_n + F_p} $$

with:
\begin{itemize}
   \item $T_p$ the number of true positives (the bounding boxes correctly localized)
   \item $F_p$ the number of false positives (the predicted bounding boxes incorrectly localized)
   \item $F_n$ the number of false negative (the ground truth bounding boxes not localized)
\end{itemize}

Note that given the convention from \cite{pascalVoc2012}, if more than one predicted bounding box overlaps the same ground truth bounding box, only one will be considered as $T_P$, the rest will be $F_P$s.

\subsection{Classification metrics}

% http://scikit-learn.org/stable/modules/cross_validation.html
cross validation
accuracy
% http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion\_matrix.html
confusion matrix

\section{Results}
\subsection{Food segmentation}

For the three metrics:
Accuracy: 0.73 \%
Precision: 0.74 \%
Recall:  0.79 \%

In \cite{Bolanos2016}, the authors use fine-tuned pre-trained Deep Neural Network and obtain around:
Accuracy: 60 \%
Precision: 80 \%
Recall: 70 \%

\subsection{Classification}

For using 10 fold cross validation
without parameters optimization

using LBP (98 bins) + HS (30 * 30 bins) + mean and variance of each RGB channel + Hu-moments
\begin{itemize}
    \item random forest: 21 \% (250 trees, gini)
    \item decision tree: 6 \% (gini)
    \item k-nearest neighborhood: (k=10, distance metric: minkowski, weights of each neighborhood point: uniform): 10 \% and 16 \% with hyperparameter optimization
    \item SGD classifier:  12 \%
    \item Gaussian Naive Bayesian: 4 \%
    \item Linear SVM: 9 \% (no kernel trick)
    \item AdaBoost with decision tree: 4 \% (SAMME.R algorithm)
\end{itemize}

using a 2500-word codebook, root-sift, k-mean, RF (500 trees): 10 \% 

using the CNN + Random forest (500 trees): 49 \%

In \cite{Bolanos2016}, the authors use fine-tuned pre-trained Deep Neural Network and obtain 63 \% accuracyon UEC FOOD-256.

In \cite{Yanai2015}, the authors use fine-tuned pre-trained Deep Neural Network and obtain 67 \% accuracyon UEC FOOD-256.


\subsection{Segmentation followed by classification}

CNN Segmenter + CNN feature descriptor + RF classifier

Result: 0.27 \% (0.73 \% accuracy for segmentation, 0.37 \% for classifier)

Accuracy: 0.73328912
Precision: 0.74412334
Recall:  0.7963661

accuracy: 0.37
precision: 0.54
recall: 0.45
f1-score: 0.41

Top 5 :
french fries 0.93006986503
beef bowl 0.951754344221
hamburger 0.954545415101
rice 0.989278742795
miso soup 0.989988865517

Least 5:
meatloaf 0.0
grilled eggplant 0.0
mozuku 0.0
chicken cutlet 0.0
tanmen 0.00943396137415

134 35 clear soup || miso soup 0.830188600926
124 35 zoni || miso soup 0.745613969683
156 35 oshiruko or red bean soup || miso soup 0.71717164473
88 35 Japanese tofu and vegetable chowder || miso soup 0.591549254116
135 35 yudofu || miso soup 0.572727220661
89 35 pork miso soup || miso soup 0.568345282853
82 5 cutlet curry || beef curry 0.54411760705
23 22 beef noodle || ramen noodle 0.503703666392
238 11 kaya toast || toast 0.453488319362
153 86 Caesar salad || green salad 0.444444389575

\cite{Bolanos2016} : accuracy 36.84 \%, 54.44 \% precision, Recall 50.86 \%


